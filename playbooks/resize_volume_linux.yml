
# =============================================================================
# Playbook: Resize EBS Volume and Expand Linux Filesystem (All Distros)
# Author:  Rennie (with Copilot assist)
# Purpose: Show clear logs in AAP of the final AWS and Linux disk sizes
# Vars expected: instance_ip_address, new_size_gb, (optional) volume_id, (optional) ansible_user
# =============================================================================

# PLAY 1: AWS Infrastructure Modification
- name: AWS Infrastructure - Resize Linux EBS Volume
  hosts: localhost
  connection: local
  gather_facts: false
  vars:
    region: "eu-west-1"
    target_ip: "{{ instance_ip_address }}"
    target_new_size: "{{ new_size_gb | int }}"
    survey_volume_id: "{{ volume_id | default('') }}"

  tasks:
    - name: Get instance details by public IP
      amazon.aws.ec2_instance_info:
        region: "{{ region }}"
        filters:
          ip-address: "{{ target_ip }}"
      register: instance_info

    - name: Fail if instance not found
      ansible.builtin.fail:
        msg: "No EC2 instance found with IP {{ target_ip }} in {{ region }}"
      when: instance_info.instances | length == 0

    - name: Set volume and zone facts
      ansible.builtin.set_fact:
        target_zone: "{{ instance_info.instances[0].placement.availability_zone }}"
        final_volume_id: >-
          {{
            survey_volume_id if (survey_volume_id | length > 5) else
            (
              instance_info.instances[0].block_device_mappings
              | selectattr('device_name', 'equalto', instance_info.instances[0].root_device_name)
              | map(attribute='ebs.volume_id')
              | first
            )
          }}

    - name: DEBUG - Requested resize
      ansible.builtin.debug:
        msg: "Attempting to resize volume {{ final_volume_id }} to {{ target_new_size }} GB in {{ target_zone }}"

    - name: Modify EBS volume in AWS
      amazon.aws.ec2_vol:
        region: "{{ region }}"
        zone: "{{ target_zone }}"
        id: "{{ final_volume_id }}"
        volume_size: "{{ target_new_size }}"
      register: aws_resizing

    - name: Small pause before polling AWS for new size
      ansible.builtin.pause:
        seconds: 10
      when: aws_resizing.changed

    - name: AWS VERIFICATION - Poll updated EBS volume size until it matches
      amazon.aws.ec2_vol_info:
        region: "{{ region }}"
        volume_ids:
          - "{{ final_volume_id }}"
      register: updated_volume_info
      until: (updated_volume_info.volumes is defined)
             and (updated_volume_info.volumes | length > 0)
             and ((updated_volume_info.volumes[0].size | int) >= (target_new_size | int))
      retries: 20
      delay: 15

    - name: LOG - Show new AWS volume size
      ansible.builtin.debug:
        msg: "AWS confirms volume {{ final_volume_id }} is now {{ updated_volume_info.volumes[0].size }} GB"

    - name: Add host to dynamic inventory for Play 2
      ansible.builtin.add_host:
        name: "{{ target_ip }}"
        groups: target_nodes
        ansible_user: "{{ ansible_user | default('ubuntu') }}"
        ansible_ssh_common_args: "-o StrictHostKeyChecking=no"
        host_volume_id: "{{ final_volume_id }}"
        requested_size: "{{ target_new_size }}"
        aws_confirmed_size: "{{ updated_volume_info.volumes[0].size }}"
        region: "{{ region }}"

# PLAY 2: OS Level Expansion & Verification
- name: OS Configuration - Expand Filesystem
  hosts: target_nodes
  become: true
  gather_facts: true

  tasks:
    # --- Ensure growpart is available on all distros ---
    - name: Try install growpart (Debian/Ubuntu - cloud-guest-utils)
      ansible.builtin.package:
        name: cloud-guest-utils
        state: present
      when: ansible_os_family == "Debian"
      ignore_errors: true

    - name: Try install growpart (RHEL/Alma/Rocky/Amazon/SUSE - cloud-utils-growpart)
      ansible.builtin.package:
        name: cloud-utils-growpart
        state: present
      when: ansible_os_family != "Debian"
      ignore_errors: true

    - name: Fallback - Try install generic cloud-utils (provides growpart on some distros)
      ansible.builtin.package:
        name: cloud-utils
        state: present
      ignore_errors: true

    - name: Ensure filesystem tools are present (best-effort)
      ansible.builtin.package:
        name:
          - xfsprogs
          - e2fsprogs
        state: present
      ignore_errors: true

    - name: Verify growpart is available
      ansible.builtin.command: bash -lc "command -v growpart"
      register: growpart_check
      changed_when: false
      failed_when: growpart_check.rc != 0

    # --- Expand partition and filesystem (root) ---
    - name: Expand partition and filesystem on root device
      ansible.builtin.shell: |
        set -euo pipefail

        ROOT_SRC="$(findmnt -n -o SOURCE /)"
        if [ -z "$ROOT_SRC" ]; then
          echo "Could not detect root source device"; exit 1
        fi

        # Get underlying disk name for the root partition
        PKNAME="$(lsblk -no PKNAME "$ROOT_SRC" | head -n1)"
        if [ -z "$PKNAME" ]; then
          # Fallback: strip partition numbers/suffix from device path
          PKNAME="$(basename "$ROOT_SRC" | sed 's/[0-9]*$//' | sed 's/p$//')"
        fi
        DEV="/dev/${PKNAME}"

        # Detect partition number for the root partition
        PARTNUM="$(lsblk -no PARTNUM "$ROOT_SRC" | head -n1)"
        if [ -z "$PARTNUM" ]; then
          # Extract trailing digits; default to 1 if still empty
          PARTNUM="$(echo "$ROOT_SRC" | sed -n 's/[^0-9]*\([0-9][0-9]*\)$/\1/p')"
          [ -z "$PARTNUM" ] && PARTNUM="1"
        fi

        echo "Root source: $ROOT_SRC"
        echo "Disk device: $DEV"
        echo "Partition #: $PARTNUM"

        # Grow the partition (idempotent; prints 'NOCHANGE' when already grown)
        growpart "$DEV" "$PARTNUM" || echo "growpart reported no change"

        # Now grow the filesystem
        FSTYPE="$(findmnt -n -o FSTYPE /)"
        if [ "$FSTYPE" = "xfs" ]; then
          xfs_growfs /
        else
          # ext2/3/4 or others supported by resize2fs
          resize2fs "$ROOT_SRC"
        fi
      register: resize_result
      changed_when: >
        ('NOCHANGE' not in resize_result.stdout | default('')) or
        ('NOCHANGE' not in resize_result.stderr | default(''))

    # --- Verification & Logging ---
    - name: VERIFICATION - Detect root disk device (path)
      ansible.builtin.shell: |
        set -e
        ROOT_SRC="$(findmnt -n -o SOURCE /)"
        PKNAME="$(lsblk -no PKNAME "$ROOT_SRC" | head -n1)"
        echo "/dev/${PKNAME}"
      register: root_disk_path
      changed_when: false

    - name: VERIFICATION - Get actual expanded physical disk size
      ansible.builtin.command: lsblk -dn -o SIZE {{ root_disk_path.stdout }}
      register: linux_disk_size
      changed_when: false

    - name: VERIFICATION - Get filesystem size information
      ansible.builtin.command: df -hT /
      register: linux_fs_size
      changed_when: false

    - name: LOG - Linux Disk & Filesystem Size
      ansible.builtin.debug:
        msg:
          - "AWS Volume ID: {{ host_volume_id }}"
          - "Requested Size: {{ requested_size }} GB"
          - "AWS Confirmed Size: {{ aws_confirmed_size }} GB"
          - "Linux block device now reports: {{ linux_disk_size.stdout | trim }}"
          - "Filesystem info: {{ linux_fs_size.stdout_lines[1] | default(linux_fs_size.stdout | trim) }}"

    # Optional soft assertion (does not fail the job) to highlight mismatch
    - name: CHECK - Does Linux disk size match AWS confirmed size? (soft check)
      ansible.builtin.assert:
        that:
          - "'{{ (aws_confirmed_size | string) }}G' in (linux_disk_size.stdout | trim)"
        fail_msg: "Disk reports {{ linux_disk_size.stdout | trim }} but AWS says {{ aws_confirmed_size }}G"
        success_msg: "Disk size matches AWS: {{ aws_confirmed_size }}G"
      failed_when: false
      changed_when: false
``
